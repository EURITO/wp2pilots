{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data notes\n",
    "'''\n",
    "-software records without doi and storage dates were removed\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import community\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import requests\n",
    "import sys\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Project entries from OpenAire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Beautiful Soup library to parse records, retrieved from OpenAire.\n",
    "Each request results in a soup object, which then can be parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of project soups from open aire and write a soupfile for each retrieved soup\n",
    "#projects starting url: 'http://api.openaire.eu/oai_pmh?verb=ListRecords&metadataPrefix=oaf&set=ECProjects'\n",
    "def writeSoupFilesNoLimit(url, outputType):\n",
    "    session = requests.session()\n",
    "    session.keep_alive = False\n",
    "    directory = './' + outputType + 'soups/'\n",
    "    #for continuing from the last resumption token use url below\n",
    "    #url = 'http://api.openaire.eu/oai_pmh?verb=ListRecords&resumptionToken=272470|oaf|*%20AND%20(resulttypeid%20exact%20\"publication\"%20and%20funder%20exact%20\"EC\")|101000|5beec22045e3121cdfbc5abf|false|ECPublications'\n",
    "    \n",
    "    #get resumption token for the next request from the previous soup\n",
    "    obtainedtoken = getIterationToken(url,session, directory)\n",
    "    #print obtainedtoken\n",
    "    strmaxpage = obtainedtoken.split(\"|\")[0]\n",
    "    #print strmaxpage\n",
    "    maxpage = int(strmaxpage)//1000 + 1\n",
    "    #print maxpage\n",
    "    for i in range(0, maxpage):\n",
    "        url = 'http://api.openaire.eu/oai_pmh?verb=ListRecords&resumptionToken=' + obtainedtoken\n",
    "        obtainedtoken = getIterationToken(url, session, directory)\n",
    "        print obtainedtoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform resumption token into appropriate string: https://www.openarchives.org/OAI/openarchivesprotocol.html#HTTPRequestFormat\n",
    "def getGoodToken(totalstring):\n",
    "    result = totalstring.replace(' ', '%20')\n",
    "    return result;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes a request url, retrieves a soup, saves a file for that soup, returns resumption token\n",
    "def getIterationToken(url, session, directory):\n",
    "    resp = session.get(url)\n",
    "    soup = BeautifulSoup(resp.content, 'lxml')\n",
    "    nexttoken = soup.find(re.compile(\"^oai:resumptiontoken\"))\n",
    "    if nexttoken: #if nexttoken is not equal to 'None'\n",
    "        filename = directory + 'soup' + str(int(nexttoken['cursor']) + 1000) + '.txt'\n",
    "        with open(filename, 'w') as f: \n",
    "            f.write(str(soup))\n",
    "        return getGoodToken(nexttoken.text);\n",
    "    else:\n",
    "        filename = directory + 'souplast' + '.txt'\n",
    "        with open(filename, 'w') as f: \n",
    "            f.write(str(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this endpoint url is obtained from OpenAire API webpage\n",
    "writeSoupFilesNoLimit('http://api.openaire.eu/oai_pmh?verb=ListRecords&metadataPrefix=oaf&set=ECProjects', 'projects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Publication entries from OpenAire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this endpoint url is obtained from OpenAire API webpage\n",
    "writeSoupFilesNoLimit('http://api.openaire.eu/oai_pmh?verb=ListRecords&metadataPrefix=oaf&set=ECPublications', 'publications')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Software entries from OpenAire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of software soups from open aire and write a soupfile for each retrieved soup\n",
    "#WORKS IF THE NUMBER OF RECORDS IS < 10000\n",
    "def writeSoupFiles(outputType):\n",
    "    soups = list()\n",
    "    maxpages = 100\n",
    "    pagesize = 500 #1000 causes memory error for jupyter\n",
    "    i = 1\n",
    "    #for i in range(1, maxpages+1):\n",
    "    while i < maxpages+1:\n",
    "        requestring = 'http://api.openaire.eu/search/' + outputType + '?page=' + str(i) + '&size=' + str(pagesize) + '&hasECFunding=true'\n",
    "        print requestring\n",
    "        resploop = requests.get(requestring)\n",
    "        souploop = BeautifulSoup(resploop.content, 'lxml')\n",
    "        filename = './' + outputType + 'soups/' + 'soup' + str(i) + '.txt'\n",
    "        if i==1:# just for the first iteration, as we want to get the total number of records\n",
    "            total = souploop.find('total')\n",
    "            maxpages = int(total.text)//pagesize + 1\n",
    "        print i,\"/\", maxpages\n",
    "        with open(filename, 'w') as f: \n",
    "            f.write(str(souploop))\n",
    "        i+=1\n",
    "        #soups.append(souploop)\n",
    "    #return soups;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeSoupFiles('software')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test cell\n",
    "'''resp = requests.get('http://api.openaire.eu/oai_pmh?verb=ListRecords&resumptionToken=46499|oaf|*%20AND%20(oaftype%20exact%20\"project\"%20and%20funder%20exact%20\"EC\")|46000|5c0a0349dc92c50c38b1ec20|false|ECProjects')\n",
    "soup = BeautifulSoup(resp.content, 'lxml')\n",
    "nexttoken = soup.find(re.compile(\"^oai:resumptiontoken\"))\n",
    "print nexttoken\n",
    "directory = './' + 'projects' + 'soups/'\n",
    "if nexttoken: #if nexttoken is not none\n",
    "    print 'not last'\n",
    "else:\n",
    "    print 'last'\n",
    "    filename = directory + 'souplast' + '.txt'\n",
    "    with open(filename, 'w') as f: \n",
    "        f.write(str(soup))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
