{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data notes\n",
    "nodelist length before graph - 261036\n",
    "nodelist length after graph - 258619, duplicates were removed automatically by networkx\n",
    "edgelist length before graph - 214843\n",
    "edgelist length after graph - 213054\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import community\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import igraph as ig\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved nodelist and edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"nodelist.pickle\",\"rb\")\n",
    "nodelist = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"edgelist.pickle\",\"rb\")\n",
    "edgelist = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create NetworkX graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#populate graph with nodes and node attributes\n",
    "G = nx.Graph()\n",
    "nodeids = list()\n",
    "for index, node in enumerate(nodelist):\n",
    "    G.add_node(node[2], name=node[2], grant=node[4], type=node[1], year=node[5], countries = str(node[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add edges to the graph\n",
    "for index, edge in enumerate(edgelist):\n",
    "    source = edge[0]\n",
    "    target = edge[1]\n",
    "    G.add_edge(source,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export NetworkX graph to graphml format for later conversion to iGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We convert NetworkX graph to iGraph because calculation of centrality measures in iGraph is significantly faster, compared to NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_graphml(G,'graph_17122018.graphml') # Export NX graph to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gix = ig.read('graph_17122018.graphml',format=\"graphml\") # Create new IG graph from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate SNA measures for all nodes of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network density\n",
    "density = Gix.density(loops=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#betweenness centrality\n",
    "betw = Gix.betweenness(vertices=None, directed=False, cutoff=None, weights=None, nobigint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eigenvector centrality\n",
    "eigen = Gix.eigenvector_centrality(directed=False, scale=True, weights=None, return_eigenvalue=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#closeness centrality\n",
    "closeness = Gix.closeness(vertices=None, mode='ALL', cutoff=None, weights=None, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a mapping between G names and Gix indices\n",
    "namesGix = Gix.vs['name']\n",
    "nodesdict = dict()\n",
    "for name in namesGix:\n",
    "    nodesdict[name] = namesGix.index(name)\n",
    "    print name, nodesdict[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mapping between nodes and indices of G\n",
    "'''nodesdict = dict()\n",
    "counter = 0\n",
    "for index,node in G.nodes(data=True):\n",
    "    nodesdict[index] = counter\n",
    "    counter = counter + 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate SNA measures for components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find all components in the graph\n",
    "components = nx.connected_components(G)\n",
    "complist = list(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leave only components that are larger than 200\n",
    "largecomplist = list()\n",
    "for component in complist:\n",
    "    if len(component)>200:\n",
    "        largecomplist.append(component)\n",
    "complist = largecomplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate SNA measures and put them into a table, where each row is a component\n",
    "df = pd.DataFrame(complist)\n",
    "for index, row in df.iterrows():\n",
    "    df.at[index,0] = index\n",
    "    df.at[index,1] = complist[index]\n",
    "    df.at[index,2] = len(complist[index])\n",
    "    df.at[index,3] = getAvgCentrality(complist[index], betw, nodesdict)\n",
    "    df.at[index,4] = getAvgCentrality(complist[index], eigen, nodesdict)\n",
    "    df.at[index,5] = getAvgCentrality(complist[index], closeness, nodesdict)\n",
    "    df.at[index,6] = len(getTypeList(complist[index]))\n",
    "    df.at[index,7] = getDiversity(complist[index])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output resulted table\n",
    "with codecs.open('EC_results_17122018.csv','wb', 'utf-8') as file:\n",
    "    file.write('componentid!componentsize!avgbetwcent!avgeigencent!avgclosecent!types!iqv')\n",
    "    file.write('\\n')\n",
    "    for index, row in df.iterrows():\n",
    "        tempstr = str(row[0]) + \"!\" + str(row[2]) + \"!\" + str(row[3]) + \"!\" + str(row[4]) + \"!\" + str(row[5]) + \"!\" + str(row[6]) + \"!\" + str(row[7])\n",
    "        tempstr = tempstr.replace(\",\", \":\")\n",
    "        file.write(tempstr)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate SNA measures per country basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load total countries list\n",
    "pickle_in = open(\"countrylist.pickle\",\"rb\")\n",
    "countrylist = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get Avg centralities for all countries\n",
    "with codecs.open('EC_results_countries_17122018.csv','wb', 'utf-8') as file:\n",
    "    file.write('Country!Avg Betw Centrality!Avg Eigenvector Centrality!Avg Closeness Centrality!Number of records')\n",
    "    file.write('\\n')\n",
    "    for country in countrylist:\n",
    "        tempstr = country + \"!\" + str(getAvgBetwCentCountry(country, betw, nodesdict)) + \"!\" + str(getAvgBetwCentCountry(country, eigen, nodesdict)) + \"!\" + str(getAvgBetwCentCountry(country, closeness, nodesdict)) + \"!\" + str(len(getCountryNodes(country)))\n",
    "        file.write(tempstr)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate average centrality\n",
    "def getAvgCentrality(component, inputbetwCent, nodesdict):\n",
    "    sum = 0\n",
    "    avg = 0\n",
    "    for entity in component:\n",
    "        sum = sum + inputbetwCent[nodesdict[entity]]\n",
    "    if len(component)>0:\n",
    "        avg = sum / len(component)\n",
    "    return avg;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the list of unique record types of the given component\n",
    "def getTypeList(component):\n",
    "    entTypeList = list()\n",
    "    for entity in component:\n",
    "        enttype = getEntityType(entity)\n",
    "        if enttype not in entTypeList:\n",
    "            entTypeList.append(enttype)\n",
    "    result = entTypeList\n",
    "    return result;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the type of the given record\n",
    "def getEntityType(entity):\n",
    "    result = G.node[entity]['type']\n",
    "    return result;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for selected country, get all nodes with those countries, find their centralities, return average\n",
    "def getAvgBetwCentCountry(country, centrality, nodesdict):\n",
    "    sum = 0\n",
    "    counter = 0\n",
    "    for index,node in G.nodes(data=True):\n",
    "        if str(node['countries']) <> 'nan':\n",
    "            if country in node['countries']:\n",
    "                sum = sum + centrality[nodesdict[index]]\n",
    "                counter = counter + 1\n",
    "    if counter > 0:\n",
    "        result = sum/counter\n",
    "    else:\n",
    "        result = -1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the number of records in the network for the given country\n",
    "def getCountryNodes(country):\n",
    "    countrynodelist = list()\n",
    "    for index,node in G.nodes(data=True):\n",
    "        if str(node['countries']) <> 'nan':\n",
    "            if country in node['countries']:\n",
    "                countrynodelist.append(node)\n",
    "    return countrynodelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntityYear(entity):\n",
    "    #G.node['entity_Name']['attribute']\n",
    "    result = G.node[entity]['year']\n",
    "    #print result\n",
    "    return result;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDiversity(component):\n",
    "    percperType = calcPctperType(component) #returns dict in the form of \"type:percentage\"\n",
    "    sumSq = calcSumSquare(component) #returns sum of squares\n",
    "    iqv = calcIQV(19,sumSq)#TODO automate K-parameter\n",
    "    return iqv;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTypeDict(component): #returns dictionary in the form of \"type:occurences\" per component\n",
    "    entTypeDict = dict()\n",
    "    for entity in component:\n",
    "        entTypeDict = addtoTypeDict(entity, entTypeDict)\n",
    "    #print entTypeList\n",
    "    return entTypeDict;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addtoTypeDict(entity, entTypeDict): #takes entity, adds the number of occurences for type of this entity to the general dictionary of types\n",
    "    enttype = getEntityType(entity)\n",
    "    if enttype not in entTypeDict:\n",
    "        entTypeDict[enttype] = 1\n",
    "    else:\n",
    "        entTypeDict[enttype] = entTypeDict[enttype] + 1\n",
    "    return entTypeDict;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that takes year as an input and returns subgraph for that year including years before that\n",
    "def getSubGraph(year):\n",
    "    subnodes = list()\n",
    "    #obtain list of nodes for that year\n",
    "    for node,fields in G.nodes(data=True):\n",
    "        print node, fields, fields['year'], year\n",
    "        if not math.isnan(fields['year']):\n",
    "            #print int(round(fields['year'])), year\n",
    "            if int(round(fields['year'])) <= int(year):\n",
    "                #print node\n",
    "                subnodes.append(node)\n",
    "    print subnodes\n",
    "    subgraph = G.subgraph(subnodes);\n",
    "    return subgraph;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets earliest year of all neighbours\n",
    "def getNeighborYear(node):\n",
    "    #print node\n",
    "    result = 5000\n",
    "    for neighbor in G.neighbors(node):\n",
    "        neighborYear = G.node[neighbor]['year']\n",
    "        #print neighbor, neighborYear\n",
    "        if result > neighborYear:\n",
    "            result = neighborYear \n",
    "    return result;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes component, returns a dictionary in form of type:percentage\n",
    "#slightly differs from SNA.xls, because in excel, grants were subtracted from the percentage - here we dont subtract\n",
    "def calcPctperType(component): \n",
    "    typeOccurDict = getTypeDict(component)\n",
    "    typePctDict = dict()\n",
    "    #find sum of occurences\n",
    "    sum = 0.0\n",
    "    for row in typeOccurDict:\n",
    "        sum = sum + typeOccurDict[row]\n",
    "    #print sum\n",
    "    for row in typeOccurDict:\n",
    "        #print row\n",
    "        #print \"occurences:\" + str(typeOccurDict[row])\n",
    "        typePctDict[row] = 100*typeOccurDict[row]/sum\n",
    "        #print \"pcts:\" + str(typePctDict[row])\n",
    "    return typePctDict;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a sum of squares for type occurence percentages for each component\n",
    "def calcSumSquare(component):\n",
    "    sumSqDict = dict()\n",
    "    pctperType = calcPctperType(component)\n",
    "    sumSQ = 0.0\n",
    "    for row in pctperType:\n",
    "        sumSQ = sumSQ + pctperType[row]*pctperType[row]\n",
    "        sumSqDict[row] = sumSQ\n",
    "        #print row\n",
    "        #print pctperType[row]\n",
    "    #print sumSQ\n",
    "    return sumSQ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcIQV(k, sumSQ):\n",
    "    iqv = k * (10000 - sumSQ)/(10000*(k-1))\n",
    "    return iqv;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first creates a subgraph for a given year, then returns the betweenness centrality for that year\n",
    "def getBetwCent(year):\n",
    "    Y = getSubGraph(year)\n",
    "    yearbetwcent = nx.betweenness_centrality(Y)\n",
    "    print year\n",
    "    print yearbetwcent\n",
    "    return yearbetwcent;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculates the list of betweenness centralities once for each, retrieved later\n",
    "def getBetwCentDict(startyear, finishyear):\n",
    "    betwcentdict = dict()\n",
    "    for year in range(startyear, finishyear):\n",
    "        yearbetwcent = getBetwCent(year)\n",
    "        betwcentdict[year] = yearbetwcent\n",
    "    return betwcentdict;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that takes a component list as an input and produces dataframe with components as rows and SNAs as columns\n",
    "def getSNAdf (incomplist, inputbetwcent):\n",
    "    subdf = pd.DataFrame(incomplist)\n",
    "    for index, row in subdf.iterrows():\n",
    "        subdf.at[index,0] = incomplist[index]\n",
    "        subdf.at[index,1] = len(incomplist[index])\n",
    "        subdf.at[index,2] = getAvgBetwCent(incomplist[index], inputbetwcent)\n",
    "        subdf.at[index,3] = len(getTypeList(incomplist[index]))\n",
    "        subdf.at[index,4] = getDiversity(incomplist[index])\n",
    "        subdf.at[index,5] = getTypeList(incomplist[index])\n",
    "    return subdf;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yeardf = getSNAdf(subcomplist, subbetwCent)\n",
    "yeardf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totaldf = getSNAdf(complist, betwCent)\n",
    "totaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of dataframes with SNA results for each year\n",
    "def getSNAdfdict(start, finish):\n",
    "    SNAdfdict = dict()\n",
    "    for year in range(start, finish):\n",
    "        yearcomplist = getSubCompList(complist, year)\n",
    "        yearbetwcent = globalbetwcentdict[year]\n",
    "        yearSNAdf = getSNAdf(yearcomplist, yearbetwcent)\n",
    "        SNAdfdict[year] = yearSNAdf\n",
    "    return SNAdfdict;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNAdfdict = getSNAdfdict(2010,2018)\n",
    "SNAdfdict[2014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input component index, output SNA measures by years for ONE component\n",
    "def getcompSNAbyYears(componentIndex, inputSNAdfdict):\n",
    "    yearlist = list(range(2010, 2018))\n",
    "    compSNAdf = pd.DataFrame(index=['component_entities','size','avgBetwCent','numberoftypes','diversity'], columns=yearlist)\n",
    "    #for yearindex,yearSNAdf in enumerate(inputSNAdflist):#for each dataframe for a year\n",
    "    for year in yearlist:\n",
    "        #get measures for componentindex\n",
    "        #compSNAdf.at['component_entities', year] = inputSNAdfdict[year][0][componentIndex]\n",
    "        compSNAdf.at['size', year] = inputSNAdfdict[year][1][componentIndex]\n",
    "        compSNAdf.at['avgBetwCent', year] = inputSNAdfdict[year][2][componentIndex]\n",
    "        compSNAdf.at['numberoftypes', year] = inputSNAdfdict[year][3][componentIndex]\n",
    "        compSNAdf.at['diversity', year] = inputSNAdfdict[year][4][componentIndex]\n",
    "        compSNAdf.at['types', year] = inputSNAdfdict[year][5][componentIndex]\n",
    "        #compSNAdf['component_entities'][yearlist[yearindex]] = inputSNAdflist[componentIndex][0]\n",
    "    return compSNAdf;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcompSNAdf = getcompSNAbyYears(1,SNAdfdict)\n",
    "outcompSNAdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input list with component indexes, output SNA measures by years for ALL SPECIFIED components\n",
    "def getcompSNAbyYearsAgg(componentIndexList, inputSNAdfdict):\n",
    "    yearlist = list(range(2010, 2018))\n",
    "    compSNAdf = pd.DataFrame(index=['component_entities','aggsize','aggavgBetwCent','aggnumberoftypes','aggdiversity'], columns=yearlist)\n",
    "    #for yearindex,yearSNAdf in enumerate(inputSNAdflist):#for each dataframe for a year\n",
    "    for year in yearlist:\n",
    "        #aggregate sizes for all the components in the list\n",
    "        compSNAdf.at['aggsize', year] = aggCompSizes(componentIndexList,inputSNAdfdict, year)\n",
    "        #aggregate avgBetwCent for all the components in the list divide by number of components\n",
    "        compSNAdf.at['aggavgBetwCent', year] = aggavgBetwCent(componentIndexList,inputSNAdfdict, year)\n",
    "        #get number of unique types for this list of components\n",
    "        compSNAdf.at['aggnumberoftypes', year] = len(countUniqueTypes(componentIndexList,inputSNAdfdict, year))\n",
    "        #calculate diversity for a given list of components\n",
    "        compSNAdf.at['aggdiversity', year] = aggDiversity(componentIndexList,inputSNAdfdict, year)\n",
    "        #compSNAdf.at['avgBetwCent', year] = inputSNAdfdict[year][2][componentIndex]\n",
    "        #compSNAdf.at['numberoftypes', year] = inputSNAdfdict[year][3][componentIndex]\n",
    "        #compSNAdf.at['diversity', year] = inputSNAdfdict[year][4][componentIndex]\n",
    "        #compSNAdf['component_entities'][yearlist[yearindex]] = inputSNAdflist[componentIndex][0]\n",
    "    return compSNAdf;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes list of component indexes, aggregates their sizes into one sum\n",
    "def aggCompSizes(componentIndexList,inputSNAdfdict,year):\n",
    "    sum = 0\n",
    "    for componentIndex in componentIndexList:\n",
    "        sum = sum + inputSNAdfdict[year][1][componentIndex]\n",
    "    return sum;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes list of component indexes, finds an average of their BetwCentralities \n",
    "def aggavgBetwCent(componentIndexList,inputSNAdfdict,year):\n",
    "    sum = 0\n",
    "    for componentIndex in componentIndexList:\n",
    "        sum = sum + inputSNAdfdict[year][2][componentIndex]\n",
    "    avg = sum / len(componentIndexList)\n",
    "    return avg;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes list of component indexes, returns a number of unique types for the whole list\n",
    "def countUniqueTypes(componentIndexList,inputSNAdfdict, year):\n",
    "    uniquetypes = list()\n",
    "    for componentIndex in componentIndexList:\n",
    "        comptypes = inputSNAdfdict[year][5][componentIndex]\n",
    "        for comptype in comptypes:\n",
    "            if comptype not in uniquetypes:\n",
    "                uniquetypes.append(comptype)\n",
    "    return uniquetypes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes list of component indexes, returns diversity based on number of unique types\n",
    "def aggDiversity(componentIndexList,inputSNAdfdict, year):\n",
    "    uniquetypes = countUniqueTypes(componentIndexList,inputSNAdfdict, year)\n",
    "    totalcompentities = list()\n",
    "    #get aggregated component and pass it to getDiversity\n",
    "    for componentIndex in componentIndexList:\n",
    "        #retrieve component entities and sum them\n",
    "        compentities = inputSNAdfdict[year][0][componentIndex]\n",
    "        for compentity in compentities:\n",
    "            totalcompentities.append(compentity)\n",
    "    #for each type, count entities of this type\n",
    "    typeOccurrences = getTypeDict(totalcompentities) #dictionary with types and their occurences\n",
    "    aggdiversity = getDiversity(totalcompentities)\n",
    "    #print len(totalcompentities)\n",
    "    #print typeOccurrences\n",
    "    #print aggdiversity\n",
    "    return aggdiversity;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that takes list of components, and outputs another list of components, \n",
    "#where each component only has nodes with a year that is equal or earlier to the specified year\n",
    "def getSubCompList(complist, year):\n",
    "    outcomplist = list()\n",
    "    for index, component in enumerate(complist):\n",
    "        tempcomp = list()\n",
    "        for entity in component:\n",
    "            #if entity.year is less or equal to the specified year, put into resulting component\n",
    "            if getEntityYear(entity) <= year:\n",
    "                #put entity into component\n",
    "                tempcomp.append(entity)\n",
    "            #put new component into output component list\n",
    "            #print index, tempcomp\n",
    "        outcomplist.append(tempcomp)\n",
    "    #print len(complist)\n",
    "    #print outcomplist\n",
    "    return outcomplist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
